\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.

%%% PACKAGES
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

%%% COMMMANDS
\newcommand{\macheps}{\epsilon_{\mathrm{mach}}}
\newcommand{\tmacheps}{\tilde{\epsilon}_{\mathrm{mach}}}
\newcommand{\unlambda}{\lambda_{\mathrm{un}}}
\newcommand{\etamax}{\eta_{\mathrm{max}}}
\newcommand{\fl}{\operatorname{fl}}
\newcommand{\vc}[1]{\textbf{#1}}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{defn}{Definition}[section]
\newtheorem{conj}{Conjecture}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{rem}{Remark}

%%% CODE
\usepackage{minted}
\usemintedstyle{tango}
\usepackage{xcolor} % to access the named colour LightGray
\definecolor{LightGray}{gray}{0.9}
    
%%% DOCUMENT  
\begin{document}
\title{LAProof: a library of formal proofs of accuracy and correctness for sparse linear algebra programs.\\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle

\begin{abstract}
This paper reports on the development of a library of formal proofs of accuracy for basic linear algebra operations. 
\end{abstract}

\begin{IEEEkeywords}
rounding error analysis, formal verification, floating point arithmetic, program verification
\end{IEEEkeywords}

\section{Introduction}\label{sec:introduction}
Numerical linear algebra is widely used across computational disciplines and is serving an increasingly important role in emerging applications for embedded systems. For the most common low-level linear algebra operations, such as the inner product and the matrix-vector product, the Basic Linear Algebra Subprograms (BLAS)~\cite{blas02,blast} provide a modular, reliable standard defining a set of the most common linear algebra operations. The software layer implementing the operations defined by BLAS is often highly-optimized and architecture specific, serving as an interface between hardware and application software. While implementations of BLAS may differ in practice, the numerical accuracy of an implementation should remain unchanged with respect to widely accepted rounding error bounds. In this paper, we report on our development of the Linear Algebra Proof Library (LAProof) , a library of formal proofs of rounding error analyses for basic linear algebra operations. The purpose of the LAProof library is to serve as a modular, portable \emph{proof layer} between the verification of application software and the verification of programs implementing operations defined by BLAS. The LAProof library makes the following contributions 

\begin{itemize}
    \item \emph{Backward and mixed backward-forward error bounds.} Previous formal rounding error analyses have exclusively focused on forward error bounds (see related work in Section \ref{sec:relatedwork}). In our development of LAProof we chose to focus on providing backward and mixed backward-forward error bounds. This choice was advantageous from both the perspective of proof engineering and numerical analysis, as it preserves the separation of rounding errors from the structural conditions of the mathematical problem being solved by the application software. Furthermore, forward error bounds can be derived directly from backward and mixed backward-forward error bounds; our library also supplies forward error bounds for each operation. 
    \item \emph{No linearization of error terms.} The rounding error associated with a sequence of operations accumulates errors as products of terms of the form $(1+\delta_i)$, where the magnitude of each $\delta_i$ is uniformly upper-bounded by the unit roundoff, $u$. Typically, numerical analysts simply linearize the product of these terms, approximating the error in $n$ operations by $nu + \mathcal{O}(u^2)$. In LAProof we avoid such approximations, giving clients of the library access to error analyses that fully characterize the accumulation of error in any sequence of operations. 
    \item \emph{Minimal Assumptions \& Soundness.} The LAProof library is fully developed inside of the Coq proof assistant, and assumes only the Flocq~\cite{flocq} specification of the IEEE 754 standard~\cite{IEEEstd} for floating point arithmetic. The rounding error analysis provided by LAProof is therefore sound with respect to the IEEE-754 standard: the rounding error bounds provided by LAProof hold for IEEE 754 arithmetic so long as the Flocq specification is assumed to be correct. Furthermore, the error bounds provided by LAProof do not assume the absence of underflow; although the proofs assume the absence of overflow, we provide a concrete example of how this assumption can be discharged for operations where numerical bounds on the terms in a linear algebra expression are known (see Section \ref{sec:sparse}. 
\end{itemize}

In addition to the LAProof library, this paper makes the following contributions 
\begin{itemize}
    \item The verification of a C program implementing matrix-vector multiplication that utilizes the compressed row storage (CRS) format. 
\end{itemize}

We admit to the following limitations.
\begin{itemize}
    \item no relative error bounds
    \item no rounding error bounds in complex arithmetic 
    \item no mixed precision
    \item no triangular solve or rotations
\end{itemize}

\section{Library Overview and Functionality}

\subsection{Notation \& Error Model}\label{sec:notation}
Throughout the paper we use the following notation for a binary IEEE 754 format with precision $p$ and maximum exponent $e$. 
\begin{description}
  \item $u$ =  unit roundoff ($2^{-p})$
  \item $\eta$ = underflow threshold ($2^{3-e-p-1})$
  \item $\mathbb{F}_{p,e}$ = exactly representable numbers in the format
\end{description}

We use the standard rounding error model for floating-point arithmetic:
\begin{align}
    \fl(a \ op \ b) = (a \ & op \ b)(1 + \delta) + \epsilon \label{eq:errormodel} \\  
    \quad |\delta| \le u, \ |\epsilon| \le \eta, \ \delta \epsilon = 0 &, \  op \in \{+, -, \times, / , \sqrt{}\} \nonumber, 
\end{align}
where $\delta,\epsilon = 0$ for $op \in \{+, -\} $. We carry out our formal error analysis in Coq, which ensures that the model in equation (\ref{eq:errormodel}) holds for IEEE arithmetic~\cite{IEEEstd} as specified by Flocq~\cite{flocq}. By using Flocq we inherit the guarantee that $\fl(a \ op \ b)$ is the correctly rounded\footnote{we assume round to nearest, ties breaking even} result of $a \ op \ b$.

We express our error bounds using the functions $h_{p,e}(n)$ and $g_{p,e}(n,m)$ to represent the accumulation of error from rounding normal and denormal numbers, respectively:
\begin{align}
    h_{p,e}(n) = ((1 + u) ^n - 1). \label{eq:hdef} \\
    g_{p,e}(n,m)= n\eta (1 + h_{p,e}(m)). \label{eq:gdef}
\end{align}

\subsection{Vector Operations}
For the interface referred to as the Level-1 BLAS, we provide formal rounding error analyses for the operations listed in Table \ref{tab:vec}. The three core vector operations are inner (dot) product ($r \leftarrow x^T y$), scaled vector addition ($r \leftarrow \alpha x + \beta y )$, and summation $(r \leftarrow \sum_{i} x_i)$. We provide mixed backward-forward error bounds for the inner product and scaled vector addition. Given that addition and subtraction are exact for denormal numbers, we are able to provide a strict backward error bound for summation. The error analyses for the remaining operations listed in Table \ref{tab:vec} follow by composing the analyses of the three core operations. 

\begin{table}[htbp]
\caption{Vector Operations}
\begin{center}
\setlength{\tabcolsep}{0.5em} % for the horizontal padding
{\renewcommand{\arraystretch}{1.4}% for the vertical padding
\begin{tabular}{|c|c|}
\hline
     DOT & $r \leftarrow x^T y$   \\
          \hline
     SUM & $ r \leftarrow \sum_{i} x_i $   \\
     \hline
     AXPY & $r \leftarrow \alpha x + \beta y $   \\
\hline
    DOT\_AXPY & $r \leftarrow  \alpha z + \beta x^T y$   \\
\hline
     VNRM1 & $r \leftarrow ||x||_1$   \\ 
     VNRM2 &  $r \leftarrow ||x||_2 $   \\ 
     \hline
     \end{tabular} }
\label{tab:vec}
\end{center}
\end{table}

We prove the following mixed backward-forward error bound for the inner product of two vectors assuming the absence of overflow. 

\begin{theorem}[\textbf{bfDOT}] For any two vectors $\tilde{\textbf{u}}, \tilde{\textbf{v}} \in \mathbb{F}_{p,e}^n$, the vectors $w,d \in \mathbb{R}^n$ and real number $c \in \mathbb{R}$ exist such that  
\[ \tilde{\textbf{u}} \odot \tilde{\textbf{v}} = \tilde{\textbf{u}} \cdot \textbf{w}  + {{c}}\] where $|c| \le g_{p,e} (n,n)$ and every $i^{th}$ element of $\vc{w}$ respects the bound $ {w}_i = u_i (1 + d_i)$ with $|d_i| \le h_{p,e}(n)$. \label{thm:bfDOT}
\end{theorem}
We prove the following as corollaries to theorem \ref{thm:bfDOT}   
\paragraph{Forward error}
\paragraph{Sparsity} Assuming that one of the vectors $\tilde{\textbf{u}}, \tilde{\textbf{v}} \in \mathbb{F}_{p,e}^n$ is sparse, we prove the theorem $\textbf{sbfDOT}$, in which the error functions $g_{p,e}$ and $h_{p,e}$ in theorem $\textbf{bfDOT}$ are parameterized by the vector with the largest number of non-zero elements. 
\paragraph{Fused-multiply add (FMA)}


\subsection{Matrix-Vector Operations}\label{sec:matvec}
For the interface referred to as the Level-2 BLAS, we provide formal proofs of rounding error bounds for the operations listed in Table \ref{tab:matvec}. The core operation is the matrix-vector product $r \leftarrow  A x$. A mixed backward-forward error bound for the matrix-vector product is easily derived from the error analysis for the inner product from the previous section~\cite[sec 3.5]{higham_book}. We also provide error analyses for the scaled matrix additions $r  \leftarrow \alpha A x + \beta y$ and $r  \leftarrow \alpha A x + \beta B y$ .
\begin{table}[htbp]
\caption{Matrix-Vector Operations}
\begin{center}
\setlength{\tabcolsep}{0.5em} % for the horizontal padding
{\renewcommand{\arraystretch}{1.4}% for the vertical padding
\begin{tabular}{|c|c|c|}
\hline
    MV & $r \leftarrow A x$   \\
\hline         
&  $ r  \leftarrow \alpha A x + \beta y$    \\ 
\hline
&  $r  \leftarrow \alpha A x + \beta B y$    \\ 
\hline
\end{tabular} }
\label{tab:matvec}
\end{center}
\end{table}

\subsection{Matrix Operations}\label{sec:mat}
For the interface referred to as the Level-3 BLAS, we provide formal rounding error analyses for the operations listed in Table \ref{tab:mat}. The core operations are the matrix-matrix product ($R \leftarrow  A B$) and the scaled matrix-matrix addition ($R \leftarrow \alpha A + \beta B$); analyses for the remaining operations are derived from the analyses of these core operations.

\begin{table}[htbp]
\caption{Matrix Operations}
\begin{center}
\setlength{\tabcolsep}{0.5em} % for the horizontal padding
{\renewcommand{\arraystretch}{1.4}% for the vertical padding
\begin{tabular}{|c|c|}
\hline
    MM & $R \leftarrow  A B$   \\
\hline         
&  $R \leftarrow \alpha A + \beta B$    \\ 
\hline
&  $R \leftarrow \alpha A B + \beta C$   \\ 
\hline
MNRM2 &  $R  \leftarrow ||A||_2$     \\ 
MNRM1 &  $R  \leftarrow ||A||_1$       \\ 
MNRMI &  $R  \leftarrow ||A||_\infty$   \\ 

\hline
\end{tabular} }
\label{tab:mat}
\end{center}
\end{table}

\section{CRS Example}\label{sec:sparse}
We express matrix-vector multiplication in Coq as a functional program 
\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{coq}
Definition MV (m: matrix) (v: vector) : vector :=
      map (fun row => DOT row v) m.
\end{minted}
 
\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
bgcolor=LightGray,
fontsize=\footnotesize,
linenos
]{coq}
Definition DOT (u v: list F) : R :=
    let uv := (List.combine u v) in
    let f  := fun s xy => add (mul xy.1 xy.2) s
    fold_left f uv.
\end{minted}

\section{Related Work}\label{sec:relatedwork}

\begin{itemize}
    \item formal linear algebra proofs  \cite{roux_15}
\end{itemize}

\section{Conclusion}

\section*{Acknowledgments}




\bibliographystyle{IEEEtran}
\bibliography{bib.bib}


\end{document}
